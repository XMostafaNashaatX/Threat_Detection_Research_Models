{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d77f456e",
      "metadata": {
        "id": "d77f456e",
        "outputId": "e87de76c-e618-41da-b335-15aad9c48450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in ./anaconda3/lib/python3.11/site-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (1.26.4)\n",
            "Requirement already satisfied: face_recognition in ./anaconda3/lib/python3.11/site-packages (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in ./anaconda3/lib/python3.11/site-packages (1.3.0)\n",
            "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (4.65.0)\n",
            "Requirement already satisfied: matplotlib in ./anaconda3/lib/python3.11/site-packages (3.7.2)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in ./anaconda3/lib/python3.11/site-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in ./anaconda3/lib/python3.11/site-packages (from face_recognition) (8.0.4)\n",
            "Requirement already satisfied: dlib>=19.7 in ./anaconda3/lib/python3.11/site-packages (from face_recognition) (19.24.6)\n",
            "Requirement already satisfied: Pillow in ./anaconda3/lib/python3.11/site-packages (from face_recognition) (9.4.0)\n",
            "Requirement already satisfied: scipy>=1.5.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python numpy face_recognition scikit-learn tqdm matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bea4e28",
      "metadata": {
        "id": "2bea4e28"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "class FaceAnalysisSystem:\n",
        "    \"\"\"\n",
        "    A system inspired by BANE for face detection, feature extraction,\n",
        "    and matching across image collections.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, match_threshold=0.67, quality_threshold=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the face analysis system.\n",
        "\n",
        "        Parameters:\n",
        "        - match_threshold: Threshold above which two faces are considered a match (0 to 1)\n",
        "        - quality_threshold: Threshold for face quality to be considered valid\n",
        "        \"\"\"\n",
        "        self.match_threshold = match_threshold\n",
        "        self.quality_threshold = quality_threshold\n",
        "\n",
        "    def detect_face(self, image_path):\n",
        "        \"\"\"\n",
        "        Detect a face in an image and return its location.\n",
        "        For pre-cropped faces, we'll assume the entire image is the face.\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            return None, None\n",
        "\n",
        "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # For pre-cropped faces, we'll use the entire image\n",
        "        h, w, _ = rgb_image.shape\n",
        "        face_location = (0, w, h, 0)  # top, right, bottom, left format\n",
        "\n",
        "        return rgb_image, face_location\n",
        "\n",
        "    def calculate_face_quality(self, face_image):\n",
        "        \"\"\"\n",
        "        Calculate a quality score for a face.\n",
        "\n",
        "        This is a simplified version since we don't have access to DSTG's algorithm.\n",
        "        We'll use metrics like face size, image sharpness, and brightness as proxies for quality.\n",
        "        \"\"\"\n",
        "        # Face size (larger is generally better for recognition)\n",
        "        h, w, _ = face_image.shape\n",
        "        size_score = min(1.0, (h * w) / (224 * 224))  # Normalize size\n",
        "\n",
        "        # Image sharpness using Laplacian variance (higher is sharper)\n",
        "        gray = cv2.cvtColor(face_image, cv2.COLOR_RGB2GRAY)\n",
        "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        sharpness_score = min(1.0, laplacian_var / 500)  # Normalize sharpness\n",
        "\n",
        "        # Brightness and contrast\n",
        "        brightness = np.mean(gray) / 255.0\n",
        "        contrast = np.std(gray) / 128.0\n",
        "        brightness_score = 1.0 - 2.0 * abs(0.5 - brightness)  # Penalize too bright or too dark\n",
        "        contrast_score = min(1.0, contrast)\n",
        "\n",
        "        # Combine scores (you may want to weight these differently)\n",
        "        quality_score = 0.3 * size_score + 0.3 * sharpness_score + 0.2 * brightness_score + 0.2 * contrast_score\n",
        "\n",
        "        return quality_score\n",
        "\n",
        "    def extract_facial_features(self, rgb_image, face_location):\n",
        "        \"\"\"\n",
        "        Extract facial features from a detected face.\n",
        "\n",
        "        Returns:\n",
        "        - face_encoding: facial feature vector\n",
        "        - quality_score: estimated quality of the face image\n",
        "        \"\"\"\n",
        "        # Extract the face from the image\n",
        "        top, right, bottom, left = face_location\n",
        "        face_image = rgb_image[top:bottom, left:right]\n",
        "\n",
        "        # Calculate face quality\n",
        "        quality_score = self.calculate_face_quality(face_image)\n",
        "\n",
        "        # Extract face encoding (embedding)\n",
        "        face_encoding = face_recognition.face_encodings(rgb_image, [(top, right, bottom, left)])\n",
        "\n",
        "        if len(face_encoding) == 0:\n",
        "            return None, quality_score\n",
        "\n",
        "        return face_encoding[0], quality_score\n",
        "\n",
        "    def match_faces(self, encoding1, encoding2):\n",
        "        \"\"\"\n",
        "        Match two face encodings and return a similarity score.\n",
        "\n",
        "        The score is transformed to be between -1 and 1, where higher values indicate more similarity.\n",
        "        \"\"\"\n",
        "        # Calculate cosine similarity between encodings\n",
        "        similarity = cosine_similarity([encoding1], [encoding2])[0][0]\n",
        "\n",
        "        # Transform to range [-1, 1] as specified in the paper\n",
        "        # face_recognition distances are already 0-1 range where lower means more similar\n",
        "        # so we need to invert and rescale\n",
        "        transformed_score = 2 * similarity - 1\n",
        "\n",
        "        return transformed_score\n",
        "\n",
        "    def process_image_collection(self, image_dir, label=None):\n",
        "        \"\"\"\n",
        "        Process a collection of images (e.g., frames from one video).\n",
        "\n",
        "        Returns:\n",
        "        - representative_faces: list of (encoding, quality, path) for the best face of each person\n",
        "        - all_faces: all detected faces with their encodings, qualities, and paths\n",
        "        \"\"\"\n",
        "        all_faces = []  # Store all detected faces\n",
        "\n",
        "        # Get all image files\n",
        "        image_files = [f for f in os.listdir(image_dir)\n",
        "                       if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "        # Process every image\n",
        "        for image_file in tqdm(image_files, desc=f\"Processing images in {os.path.basename(image_dir)}\"):\n",
        "            image_path = os.path.join(image_dir, image_file)\n",
        "\n",
        "            # Detect face in the image\n",
        "            rgb_image, face_location = self.detect_face(image_path)\n",
        "            if rgb_image is None:\n",
        "                continue\n",
        "\n",
        "            # Extract facial features and quality score\n",
        "            face_encoding, quality_score = self.extract_facial_features(rgb_image, face_location)\n",
        "\n",
        "            if face_encoding is not None and quality_score >= self.quality_threshold:\n",
        "                all_faces.append({\n",
        "                    'encoding': face_encoding,\n",
        "                    'quality': quality_score,\n",
        "                    'path': image_path,\n",
        "                    'label': label\n",
        "                })\n",
        "\n",
        "        # Identify duplicate faces (same person in different images)\n",
        "        # Group faces by identity\n",
        "        identity_groups = self.group_faces_by_identity(all_faces)\n",
        "\n",
        "        # For each identity group, keep the face with the highest quality score\n",
        "        representative_faces = []\n",
        "        for identity_group in identity_groups:\n",
        "            best_face = max(identity_group, key=lambda x: x['quality'])\n",
        "            representative_faces.append(best_face)\n",
        "\n",
        "        return representative_faces, all_faces\n",
        "\n",
        "    def group_faces_by_identity(self, faces):\n",
        "        \"\"\"\n",
        "        Group faces that belong to the same person based on similarity.\n",
        "\n",
        "        Returns a list of lists, where each inner list contains faces of the same person.\n",
        "        \"\"\"\n",
        "        if not faces:\n",
        "            return []\n",
        "\n",
        "        # Start with each face in its own group\n",
        "        groups = [[face] for face in faces]\n",
        "\n",
        "        # Merge groups if faces match across groups\n",
        "        i = 0\n",
        "        while i < len(groups):\n",
        "            j = i + 1\n",
        "            while j < len(groups):\n",
        "                # Check if any face in group i matches any face in group j\n",
        "                match_found = False\n",
        "                for face_i in groups[i]:\n",
        "                    for face_j in groups[j]:\n",
        "                        match_score = self.match_faces(face_i['encoding'], face_j['encoding'])\n",
        "                        if match_score >= self.match_threshold:\n",
        "                            # Merge group j into group i\n",
        "                            groups[i].extend(groups[j])\n",
        "                            groups.pop(j)\n",
        "                            match_found = True\n",
        "                            break\n",
        "                    if match_found:\n",
        "                        break\n",
        "\n",
        "                if not match_found:\n",
        "                    j += 1\n",
        "            i += 1\n",
        "\n",
        "        return groups\n",
        "\n",
        "    def compare_collections(self, collection1, collection2):\n",
        "        \"\"\"\n",
        "        Compare two collections of representative faces and find matches.\n",
        "\n",
        "        Returns:\n",
        "        - matches: list of (face1, face2, score) for matched pairs above threshold\n",
        "        \"\"\"\n",
        "        matches = []\n",
        "\n",
        "        # Compare each representative face from collection1 to each from collection2\n",
        "        for face1 in collection1:\n",
        "            for face2 in collection2:\n",
        "                match_score = self.match_faces(face1['encoding'], face2['encoding'])\n",
        "\n",
        "                if match_score >= self.match_threshold:\n",
        "                    matches.append((face1, face2, match_score))\n",
        "\n",
        "        return matches\n",
        "\n",
        "    def evaluate_accuracy(self, matches, verbose=True):\n",
        "        \"\"\"\n",
        "        Evaluate the accuracy of matches based on their labels (if available).\n",
        "        \"\"\"\n",
        "        if not matches:\n",
        "            return None, None\n",
        "\n",
        "        # Count correct and incorrect matches\n",
        "        correct_matches = 0\n",
        "        incorrect_matches = 0\n",
        "\n",
        "        for face1, face2, score in matches:\n",
        "            if 'label' in face1 and 'label' in face2:\n",
        "                if face1['label'] == face2['label']:\n",
        "                    correct_matches += 1\n",
        "                else:\n",
        "                    incorrect_matches += 1\n",
        "\n",
        "        total_evaluated = correct_matches + incorrect_matches\n",
        "\n",
        "        if total_evaluated == 0:\n",
        "            if verbose:\n",
        "                print(\"No labeled faces to evaluate accuracy.\")\n",
        "            return None, None\n",
        "\n",
        "        accuracy = correct_matches / total_evaluated if total_evaluated > 0 else 0\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Match Accuracy: {accuracy:.3f} ({correct_matches}/{total_evaluated})\")\n",
        "            print(f\"False Match Rate: {incorrect_matches/total_evaluated:.3f} ({incorrect_matches}/{total_evaluated})\")\n",
        "\n",
        "        return accuracy, incorrect_matches/total_evaluated\n",
        "\n",
        "    def visualize_matches(self, matches, output_dir, max_to_show=10):\n",
        "        \"\"\"\n",
        "        Visualize matches by displaying pairs of matched faces side by side.\n",
        "        \"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Sort matches by score (highest first)\n",
        "        sorted_matches = sorted(matches, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # Limit the number to display\n",
        "        matches_to_show = sorted_matches[:max_to_show]\n",
        "\n",
        "        for i, (face1, face2, score) in enumerate(matches_to_show):\n",
        "            # Load images\n",
        "            img1 = cv2.imread(face1['path'])\n",
        "            img2 = cv2.imread(face2['path'])\n",
        "\n",
        "            if img1 is None or img2 is None:\n",
        "                continue\n",
        "\n",
        "            # Resize to same height if needed\n",
        "            h1, w1 = img1.shape[:2]\n",
        "            h2, w2 = img2.shape[:2]\n",
        "\n",
        "            # Choose the smaller height\n",
        "            target_height = min(h1, h2, 300)  # Limit max height\n",
        "\n",
        "            # Resize maintaining aspect ratio\n",
        "            img1 = cv2.resize(img1, (int(w1 * target_height / h1), target_height))\n",
        "            img2 = cv2.resize(img2, (int(w2 * target_height / h2), target_height))\n",
        "\n",
        "            # Create a side-by-side image with labels\n",
        "            h1, w1 = img1.shape[:2]\n",
        "            h2, w2 = img2.shape[:2]\n",
        "\n",
        "            # Create combined image\n",
        "            combined_width = w1 + w2 + 20  # 20 pixels between images\n",
        "            combined_img = np.zeros((target_height + 50, combined_width, 3), dtype=np.uint8) + 255\n",
        "\n",
        "            # Add images\n",
        "            combined_img[:h1, :w1] = img1\n",
        "            combined_img[:h2, w1+20:w1+20+w2] = img2\n",
        "\n",
        "            # Add text\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_scale = 0.6\n",
        "            label1 = face1.get('label', 'Unknown')\n",
        "            label2 = face2.get('label', 'Unknown')\n",
        "\n",
        "            cv2.putText(combined_img, f\"Match Score: {score:.3f}\", (10, target_height + 20),\n",
        "                        font, font_scale, (0, 0, 0), 1)\n",
        "            cv2.putText(combined_img, f\"Left: {label1}\", (10, target_height + 40),\n",
        "                        font, font_scale, (0, 0, 0), 1)\n",
        "            cv2.putText(combined_img, f\"Right: {label2}\", (combined_width//2, target_height + 40),\n",
        "                        font, font_scale, (0, 0, 0), 1)\n",
        "\n",
        "            # Save the combined image\n",
        "            output_path = os.path.join(output_dir, f\"match_{i+1}_score_{score:.3f}.jpg\")\n",
        "            cv2.imwrite(output_path, combined_img)\n",
        "\n",
        "        print(f\"Visualizations saved to {output_dir}\")\n",
        "\n",
        "def process_dataset(base_dir, output_dir, match_threshold=0.67):\n",
        "    \"\"\"\n",
        "    Process an entire dataset organized as:\n",
        "    base_dir/\n",
        "        emotion1/\n",
        "            image1.jpg\n",
        "            image2.jpg\n",
        "        emotion2/\n",
        "            image3.jpg\n",
        "            ...\n",
        "    \"\"\"\n",
        "    # Initialize the face analysis system\n",
        "    face_system = FaceAnalysisSystem(match_threshold=match_threshold)\n",
        "\n",
        "    # Get emotion categories (subdirectories)\n",
        "    emotion_categories = [d for d in os.listdir(base_dir)\n",
        "                         if os.path.isdir(os.path.join(base_dir, d))]\n",
        "\n",
        "    print(f\"Found emotion categories: {emotion_categories}\")\n",
        "\n",
        "    all_representative_faces = []\n",
        "    emotion_representatives = {}\n",
        "\n",
        "    # Process each emotion category\n",
        "    for emotion in emotion_categories:\n",
        "        emotion_dir = os.path.join(base_dir, emotion)\n",
        "        print(f\"\\nProcessing emotion: {emotion}\")\n",
        "\n",
        "        # Process all images in this emotion category\n",
        "        representative_faces, all_faces = face_system.process_image_collection(\n",
        "            emotion_dir, label=emotion)\n",
        "\n",
        "        print(f\"Found {len(representative_faces)} unique faces out of {len(all_faces)} total faces\")\n",
        "\n",
        "        # Save representative faces for this emotion\n",
        "        emotion_representatives[emotion] = representative_faces\n",
        "        all_representative_faces.extend(representative_faces)\n",
        "\n",
        "        # Save the processed data\n",
        "        output_file = os.path.join(output_dir, f\"{emotion}_faces.pkl\")\n",
        "        with open(output_file, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'representative_faces': representative_faces,\n",
        "                'all_faces': all_faces\n",
        "            }, f)\n",
        "\n",
        "        print(f\"Saved processed data to {output_file}\")\n",
        "\n",
        "    # Cross-emotion matching\n",
        "    print(\"\\nPerforming cross-emotion matching...\")\n",
        "    all_matches = []\n",
        "\n",
        "    # Compare each emotion category with every other\n",
        "    for i, emotion1 in enumerate(emotion_categories):\n",
        "        for j, emotion2 in enumerate(emotion_categories[i:], i):\n",
        "            if i == j:  # Skip self-comparison\n",
        "                continue\n",
        "\n",
        "            print(f\"Comparing {emotion1} vs {emotion2}\")\n",
        "            matches = face_system.compare_collections(\n",
        "                emotion_representatives[emotion1],\n",
        "                emotion_representatives[emotion2]\n",
        "            )\n",
        "\n",
        "            print(f\"Found {len(matches)} matches above threshold {face_system.match_threshold}\")\n",
        "            all_matches.extend(matches)\n",
        "\n",
        "            # Evaluate accuracy if labels are available\n",
        "            face_system.evaluate_accuracy(matches)\n",
        "\n",
        "            # Visualize some matches\n",
        "            vis_dir = os.path.join(output_dir, f\"vis_{emotion1}_vs_{emotion2}\")\n",
        "            face_system.visualize_matches(matches, vis_dir)\n",
        "\n",
        "    # Save all matches\n",
        "    all_matches_file = os.path.join(output_dir, \"all_matches.pkl\")\n",
        "    with open(all_matches_file, 'wb') as f:\n",
        "        pickle.dump(all_matches, f)\n",
        "\n",
        "    print(f\"Saved all matches to {all_matches_file}\")\n",
        "\n",
        "    return all_representative_faces, all_matches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d4973a2",
      "metadata": {
        "id": "1d4973a2",
        "outputId": "4d56dba8-638d-448f-8419-af23c58da783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting face analysis system...\n",
            "\n",
            "=== Processing TRAIN dataset ===\n",
            "Found emotion categories: ['happy', 'sad', 'fear', 'surprise', 'neutral', 'angry', 'disgust']\n",
            "\n",
            "Processing emotion: happy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in happy: 100%|███████████| 7214/7214 [01:14<00:00, 97.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 6527 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/happy_faces.pkl\n",
            "\n",
            "Processing emotion: sad\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in sad: 100%|█████████████| 4830/4830 [00:49<00:00, 97.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 4281 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/sad_faces.pkl\n",
            "\n",
            "Processing emotion: fear\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in fear: 100%|████████████| 4097/4097 [00:43<00:00, 94.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 3675 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/fear_faces.pkl\n",
            "\n",
            "Processing emotion: surprise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in surprise: 100%|████████| 3171/3171 [00:32<00:00, 96.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 2732 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/surprise_faces.pkl\n",
            "\n",
            "Processing emotion: neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in neutral: 100%|█████████| 4965/4965 [00:51<00:00, 96.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 4402 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/neutral_faces.pkl\n",
            "\n",
            "Processing emotion: angry\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in angry: 100%|███████████| 3995/3995 [00:40<00:00, 98.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 3589 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/angry_faces.pkl\n",
            "\n",
            "Processing emotion: disgust\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in disgust: 100%|███████████| 436/436 [00:04<00:00, 99.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 unique faces out of 381 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/disgust_faces.pkl\n",
            "\n",
            "Performing cross-emotion matching...\n",
            "Comparing happy vs sad\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_sad\n",
            "Comparing happy vs fear\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_fear\n",
            "Comparing happy vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_surprise\n",
            "Comparing happy vs neutral\n",
            "Found 0 matches above threshold 0.67\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_neutral\n",
            "Comparing happy vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_angry\n",
            "Comparing happy vs disgust\n",
            "Found 2 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/2)\n",
            "False Match Rate: 1.000 (2/2)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_disgust\n",
            "Comparing sad vs fear\n",
            "Found 0 matches above threshold 0.67\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_sad_vs_fear\n",
            "Comparing sad vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_sad_vs_surprise\n",
            "Comparing sad vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_sad_vs_neutral\n",
            "Comparing sad vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_sad_vs_angry\n",
            "Comparing sad vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_sad_vs_disgust\n",
            "Comparing fear vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_fear_vs_surprise\n",
            "Comparing fear vs neutral\n",
            "Found 0 matches above threshold 0.67\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_fear_vs_neutral\n",
            "Comparing fear vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_fear_vs_angry\n",
            "Comparing fear vs disgust\n",
            "Found 2 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/2)\n",
            "False Match Rate: 1.000 (2/2)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_fear_vs_disgust\n",
            "Comparing surprise vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_surprise_vs_neutral\n",
            "Comparing surprise vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_surprise_vs_angry\n",
            "Comparing surprise vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_surprise_vs_disgust\n",
            "Comparing neutral vs angry\n",
            "Found 0 matches above threshold 0.67\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_neutral_vs_angry\n",
            "Comparing neutral vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_neutral_vs_disgust\n",
            "Comparing angry vs disgust\n",
            "Found 0 matches above threshold 0.67\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_angry_vs_disgust\n",
            "Saved all matches to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/all_matches.pkl\n",
            "\n",
            "=== Processing TEST dataset ===\n",
            "Found emotion categories: ['happy', 'sad', 'fear', 'surprise', 'neutral', 'angry', 'disgust']\n",
            "\n",
            "Processing emotion: happy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in happy: 100%|███████████| 1772/1772 [00:17<00:00, 99.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 1596 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/happy_faces.pkl\n",
            "\n",
            "Processing emotion: sad\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in sad: 100%|█████████████| 1247/1247 [00:12<00:00, 98.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 1114 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/sad_faces.pkl\n",
            "\n",
            "Processing emotion: fear\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in fear: 100%|████████████| 1024/1024 [00:10<00:00, 98.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 922 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/fear_faces.pkl\n",
            "\n",
            "Processing emotion: surprise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in surprise: 100%|██████████| 831/831 [00:08<00:00, 99.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 719 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/surprise_faces.pkl\n",
            "\n",
            "Processing emotion: neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in neutral: 100%|█████████| 1233/1233 [00:12<00:00, 96.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 1097 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/neutral_faces.pkl\n",
            "\n",
            "Processing emotion: angry\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in angry: 100%|█████████████| 958/958 [00:09<00:00, 98.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 unique faces out of 860 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/angry_faces.pkl\n",
            "\n",
            "Processing emotion: disgust\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in disgust: 100%|██████████| 111/111 [00:01<00:00, 100.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 98 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/disgust_faces.pkl\n",
            "\n",
            "Performing cross-emotion matching...\n",
            "Comparing happy vs sad\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_sad\n",
            "Comparing happy vs fear\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_fear\n",
            "Comparing happy vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_surprise\n",
            "Comparing happy vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_neutral\n",
            "Comparing happy vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_angry\n",
            "Comparing happy vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_disgust\n",
            "Comparing sad vs fear\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_sad_vs_fear\n",
            "Comparing sad vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_sad_vs_surprise\n",
            "Comparing sad vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_sad_vs_neutral\n",
            "Comparing sad vs angry\n",
            "Found 2 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/2)\n",
            "False Match Rate: 1.000 (2/2)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_sad_vs_angry\n",
            "Comparing sad vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_sad_vs_disgust\n",
            "Comparing fear vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_fear_vs_surprise\n",
            "Comparing fear vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_fear_vs_neutral\n",
            "Comparing fear vs angry\n",
            "Found 2 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/2)\n",
            "False Match Rate: 1.000 (2/2)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_fear_vs_angry\n",
            "Comparing fear vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_fear_vs_disgust\n",
            "Comparing surprise vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_surprise_vs_neutral\n",
            "Comparing surprise vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_surprise_vs_angry\n",
            "Comparing surprise vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_surprise_vs_disgust\n",
            "Comparing neutral vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_neutral_vs_angry\n",
            "Comparing neutral vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_neutral_vs_disgust\n",
            "Comparing angry vs disgust\n",
            "Found 2 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/2)\n",
            "False Match Rate: 1.000 (2/2)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_angry_vs_disgust\n",
            "Saved all matches to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/all_matches.pkl\n",
            "\n",
            "=== Comparing TRAIN vs TEST datasets ===\n",
            "Found 44 matches between train and test datasets\n",
            "Match Accuracy: 0.091 (4/44)\n",
            "False Match Rate: 0.909 (40/44)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/vis_train_vs_test\n",
            "Saved train-test matches to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/train_test_matches.pkl\n",
            "\n",
            "Completed face analysis process.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # Paths\n",
        "    DATASET_DIR = \"/Users/abdelwahab/3rd-year/s2/7_emotion_dataset\"\n",
        "    TRAIN_DIR = os.path.join(DATASET_DIR, \"train\")\n",
        "    TEST_DIR = os.path.join(DATASET_DIR, \"test\")\n",
        "\n",
        "    # Create output directories\n",
        "    TRAIN_OUTPUT_DIR = os.path.join(DATASET_DIR, \"analysis_train\")\n",
        "    TEST_OUTPUT_DIR = os.path.join(DATASET_DIR, \"analysis_test\")\n",
        "    os.makedirs(TRAIN_OUTPUT_DIR, exist_ok=True)\n",
        "    os.makedirs(TEST_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    print(\"Starting face analysis system...\")\n",
        "\n",
        "    # Process train dataset\n",
        "    print(\"\\n=== Processing TRAIN dataset ===\")\n",
        "    train_faces, train_matches = process_dataset(TRAIN_DIR, TRAIN_OUTPUT_DIR)\n",
        "\n",
        "    # Process test dataset\n",
        "    print(\"\\n=== Processing TEST dataset ===\")\n",
        "    test_faces, test_matches = process_dataset(TEST_DIR, TEST_OUTPUT_DIR)\n",
        "\n",
        "    # Compare train representative faces with test representative faces\n",
        "    print(\"\\n=== Comparing TRAIN vs TEST datasets ===\")\n",
        "    face_system = FaceAnalysisSystem()\n",
        "    train_test_matches = face_system.compare_collections(train_faces, test_faces)\n",
        "\n",
        "    print(f\"Found {len(train_test_matches)} matches between train and test datasets\")\n",
        "\n",
        "    # Evaluate accuracy of train-test matches\n",
        "    face_system.evaluate_accuracy(train_test_matches)\n",
        "\n",
        "    # Visualize some train-test matches\n",
        "    vis_dir = os.path.join(DATASET_DIR, \"vis_train_vs_test\")\n",
        "    face_system.visualize_matches(train_test_matches, vis_dir, max_to_show=20)\n",
        "\n",
        "    # Save train-test matches\n",
        "    train_test_file = os.path.join(DATASET_DIR, \"train_test_matches.pkl\")\n",
        "    with open(train_test_file, 'wb') as f:\n",
        "        pickle.dump(train_test_matches, f)\n",
        "\n",
        "    print(f\"Saved train-test matches to {train_test_file}\")\n",
        "\n",
        "    print(\"\\nCompleted face analysis process.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef48bd1",
      "metadata": {
        "id": "fef48bd1",
        "outputId": "44173a0f-0e46-4c39-eef2-cea6f1c77393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: threadpoolctl in ./anaconda3/lib/python3.11/site-packages (2.2.0)\n",
            "Collecting threadpoolctl\n",
            "  Obtaining dependency information for threadpoolctl from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scikit-learn in ./anaconda3/lib/python3.11/site-packages (1.3.0)\n",
            "Collecting scikit-learn\n",
            "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/25/92/ee1d7a00bb6b8c55755d4984fd82608603a3cc59959245068ce32e7fb808/scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
            "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/2b/3e/e7247c1d4f15086bb106c8d43c925b0b2ea20270224f5186fa48d4fb5cbd/numpy-2.2.4-cp311-cp311-macosx_14_0_arm64.whl.metadata\n",
            "  Downloading numpy-2.2.4-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: threadpoolctl, scikit-learn\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 2.2.0\n",
            "    Uninstalling threadpoolctl-2.2.0:\n",
            "      Successfully uninstalled threadpoolctl-2.2.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.0\n",
            "    Uninstalling scikit-learn-1.3.0:\n",
            "      Successfully uninstalled scikit-learn-1.3.0\n",
            "Successfully installed scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade threadpoolctl scikit-learn numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a798d4c",
      "metadata": {
        "id": "1a798d4c",
        "outputId": "41eec44f-89fe-482c-eb6c-404503d54f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting face analysis system...\n",
            "\n",
            "=== Processing TRAIN dataset ===\n",
            "Found emotion categories: ['happy', 'sad', 'fear', 'surprise', 'neutral', 'angry', 'disgust']\n",
            "\n",
            "Processing emotion: happy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in happy: 100%|███████████| 7214/7214 [01:15<00:00, 95.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 6527 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/happy_faces.pkl\n",
            "\n",
            "Processing emotion: sad\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in sad: 100%|█████████████| 4830/4830 [00:50<00:00, 95.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 4281 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/sad_faces.pkl\n",
            "\n",
            "Processing emotion: fear\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in fear: 100%|████████████| 4097/4097 [00:43<00:00, 94.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 3675 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/fear_faces.pkl\n",
            "\n",
            "Processing emotion: surprise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in surprise: 100%|████████| 3171/3171 [00:33<00:00, 95.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 2732 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/surprise_faces.pkl\n",
            "\n",
            "Processing emotion: neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in neutral: 100%|█████████| 4965/4965 [00:52<00:00, 95.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 4402 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/neutral_faces.pkl\n",
            "\n",
            "Processing emotion: angry\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in angry: 100%|███████████| 3995/3995 [00:42<00:00, 94.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 3589 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/angry_faces.pkl\n",
            "\n",
            "Processing emotion: disgust\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in disgust: 100%|███████████| 436/436 [00:04<00:00, 95.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 unique faces out of 381 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/disgust_faces.pkl\n",
            "\n",
            "Performing cross-emotion matching...\n",
            "Comparing happy vs sad\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_sad\n",
            "Comparing happy vs fear\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_fear\n",
            "Comparing happy vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_surprise\n",
            "Comparing happy vs neutral\n",
            "Found 0 matches above threshold 0.67\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_neutral\n",
            "Comparing happy vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_angry\n",
            "Comparing happy vs disgust\n",
            "Found 2 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/2)\n",
            "False Match Rate: 1.000 (2/2)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_happy_vs_disgust\n",
            "Comparing sad vs fear\n",
            "Found 0 matches above threshold 0.67\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_sad_vs_fear\n",
            "Comparing sad vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_sad_vs_surprise\n",
            "Comparing sad vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_sad_vs_neutral\n",
            "Comparing sad vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_sad_vs_angry\n",
            "Comparing sad vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_sad_vs_disgust\n",
            "Comparing fear vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_fear_vs_surprise\n",
            "Comparing fear vs neutral\n",
            "Found 0 matches above threshold 0.67\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_fear_vs_neutral\n",
            "Comparing fear vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_fear_vs_angry\n",
            "Comparing fear vs disgust\n",
            "Found 2 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/2)\n",
            "False Match Rate: 1.000 (2/2)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_fear_vs_disgust\n",
            "Comparing surprise vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_surprise_vs_neutral\n",
            "Comparing surprise vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_surprise_vs_angry\n",
            "Comparing surprise vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_surprise_vs_disgust\n",
            "Comparing neutral vs angry\n",
            "Found 0 matches above threshold 0.67\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_neutral_vs_angry\n",
            "Comparing neutral vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_neutral_vs_disgust\n",
            "Comparing angry vs disgust\n",
            "Found 0 matches above threshold 0.67\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/vis_angry_vs_disgust\n",
            "Saved all matches to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_train/all_matches.pkl\n",
            "\n",
            "=== Processing TEST dataset ===\n",
            "Found emotion categories: ['happy', 'sad', 'fear', 'surprise', 'neutral', 'angry', 'disgust']\n",
            "\n",
            "Processing emotion: happy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in happy: 100%|███████████| 1772/1772 [00:18<00:00, 94.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 1596 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/happy_faces.pkl\n",
            "\n",
            "Processing emotion: sad\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in sad: 100%|█████████████| 1247/1247 [00:13<00:00, 95.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 1114 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/sad_faces.pkl\n",
            "\n",
            "Processing emotion: fear\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in fear: 100%|████████████| 1024/1024 [00:10<00:00, 93.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 922 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/fear_faces.pkl\n",
            "\n",
            "Processing emotion: surprise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in surprise: 100%|██████████| 831/831 [00:08<00:00, 95.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 719 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/surprise_faces.pkl\n",
            "\n",
            "Processing emotion: neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in neutral: 100%|█████████| 1233/1233 [00:13<00:00, 94.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 1097 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/neutral_faces.pkl\n",
            "\n",
            "Processing emotion: angry\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in angry: 100%|█████████████| 958/958 [00:10<00:00, 95.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 unique faces out of 860 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/angry_faces.pkl\n",
            "\n",
            "Processing emotion: disgust\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images in disgust: 100%|███████████| 111/111 [00:01<00:00, 97.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 unique faces out of 98 total faces\n",
            "Saved processed data to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/disgust_faces.pkl\n",
            "\n",
            "Performing cross-emotion matching...\n",
            "Comparing happy vs sad\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_sad\n",
            "Comparing happy vs fear\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_fear\n",
            "Comparing happy vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_surprise\n",
            "Comparing happy vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_neutral\n",
            "Comparing happy vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_angry\n",
            "Comparing happy vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_happy_vs_disgust\n",
            "Comparing sad vs fear\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_sad_vs_fear\n",
            "Comparing sad vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_sad_vs_surprise\n",
            "Comparing sad vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_sad_vs_neutral\n",
            "Comparing sad vs angry\n",
            "Found 2 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/2)\n",
            "False Match Rate: 1.000 (2/2)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_sad_vs_angry\n",
            "Comparing sad vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_sad_vs_disgust\n",
            "Comparing fear vs surprise\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_fear_vs_surprise\n",
            "Comparing fear vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_fear_vs_neutral\n",
            "Comparing fear vs angry\n",
            "Found 2 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/2)\n",
            "False Match Rate: 1.000 (2/2)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_fear_vs_angry\n",
            "Comparing fear vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_fear_vs_disgust\n",
            "Comparing surprise vs neutral\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_surprise_vs_neutral\n",
            "Comparing surprise vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_surprise_vs_angry\n",
            "Comparing surprise vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_surprise_vs_disgust\n",
            "Comparing neutral vs angry\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_neutral_vs_angry\n",
            "Comparing neutral vs disgust\n",
            "Found 1 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/1)\n",
            "False Match Rate: 1.000 (1/1)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_neutral_vs_disgust\n",
            "Comparing angry vs disgust\n",
            "Found 2 matches above threshold 0.67\n",
            "Match Accuracy: 0.000 (0/2)\n",
            "False Match Rate: 1.000 (2/2)\n",
            "Visualizations saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/vis_angry_vs_disgust\n",
            "Saved all matches to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/analysis_test/all_matches.pkl\n",
            "=== TRAIN Dataset Info ===\n",
            "Total faces processed: 8\n",
            "Sample face features: ['encoding', 'quality', 'path', 'label']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'quality_score'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 115\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCompleted face analysis process.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 115\u001b[0m     main()\n",
            "Cell \u001b[0;32mIn[28], line 80\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# EDA for train dataset\u001b[39;00m\n\u001b[1;32m     79\u001b[0m basic_data_info(train_faces, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m visualize_face_quality_distribution(train_faces, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m check_missing_or_corrupted_faces(train_faces, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# EDA for test dataset\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[28], line 8\u001b[0m, in \u001b[0;36mvisualize_face_quality_distribution\u001b[0;34m(faces, dataset_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_face_quality_distribution\u001b[39m(faces, dataset_name):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Visualize quality distribution of the faces in the dataset.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     qualities \u001b[38;5;241m=\u001b[39m [face[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m faces]  \u001b[38;5;66;03m# Assuming quality_score is available\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     10\u001b[0m     sns\u001b[38;5;241m.\u001b[39mhistplot(qualities, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n",
            "Cell \u001b[0;32mIn[28], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_face_quality_distribution\u001b[39m(faces, dataset_name):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Visualize quality distribution of the faces in the dataset.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     qualities \u001b[38;5;241m=\u001b[39m [face[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m faces]  \u001b[38;5;66;03m# Assuming quality_score is available\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     10\u001b[0m     sns\u001b[38;5;241m.\u001b[39mhistplot(qualities, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'quality_score'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def visualize_face_quality_distribution(faces, dataset_name):\n",
        "    \"\"\"Visualize quality distribution of the faces in the dataset.\"\"\"\n",
        "    qualities = [face['quality_score'] for face in faces]  # Assuming quality_score is available\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(qualities, bins=20, kde=True, color='blue', alpha=0.7)\n",
        "    plt.title(f'{dataset_name} Quality Score Distribution')\n",
        "    plt.xlabel('Quality Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "def basic_data_info(faces, dataset_name):\n",
        "    \"\"\"Print basic data info like total faces and features.\"\"\"\n",
        "    print(f\"=== {dataset_name} Dataset Info ===\")\n",
        "    print(f\"Total faces processed: {len(faces)}\")\n",
        "\n",
        "    # Assuming each face is a dictionary containing image-related features\n",
        "    if len(faces) > 0:\n",
        "        sample_face = faces[0]\n",
        "        print(f\"Sample face features: {list(sample_face.keys())}\")\n",
        "\n",
        "def check_missing_or_corrupted_faces(faces, dataset_name):\n",
        "    \"\"\"Check for missing or corrupted faces.\"\"\"\n",
        "    print(f\"=== {dataset_name} Missing/Corrupted Faces Check ===\")\n",
        "    missing_faces = [i for i, face in enumerate(faces) if face.get('image_data') is None]  # Assuming 'image_data' is a field\n",
        "    if missing_faces:\n",
        "        print(f\"Missing/Corrupted Faces found at indices: {missing_faces}\")\n",
        "    else:\n",
        "        print(\"No missing/corrupted faces found.\")\n",
        "\n",
        "def compare_train_test_statistics(train_faces, test_faces):\n",
        "    \"\"\"Compare statistics between train and test datasets.\"\"\"\n",
        "    print(\"\\n=== Comparing Train and Test Dataset Statistics ===\")\n",
        "\n",
        "    # Compare average quality scores between the datasets\n",
        "    train_qualities = [face['quality_score'] for face in train_faces]\n",
        "    test_qualities = [face['quality_score'] for face in test_faces]\n",
        "\n",
        "    print(f\"Train dataset average quality score: {sum(train_qualities) / len(train_qualities)}\")\n",
        "    print(f\"Test dataset average quality score: {sum(test_qualities) / len(test_qualities)}\")\n",
        "\n",
        "    # Visualize the comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(train_qualities, bins=20, kde=True, color='blue', alpha=0.6, label='Train')\n",
        "    sns.histplot(test_qualities, bins=20, kde=True, color='red', alpha=0.6, label='Test')\n",
        "    plt.title('Train vs Test Quality Score Comparison')\n",
        "    plt.xlabel('Quality Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    # Paths\n",
        "    DATASET_DIR = \"/Users/abdelwahab/3rd-year/s2/7_emotion_dataset\"\n",
        "    TRAIN_DIR = os.path.join(DATASET_DIR, \"train\")\n",
        "    TEST_DIR = os.path.join(DATASET_DIR, \"test\")\n",
        "\n",
        "    # Create output directories\n",
        "    TRAIN_OUTPUT_DIR = os.path.join(DATASET_DIR, \"analysis_train\")\n",
        "    TEST_OUTPUT_DIR = os.path.join(DATASET_DIR, \"analysis_test\")\n",
        "    os.makedirs(TRAIN_OUTPUT_DIR, exist_ok=True)\n",
        "    os.makedirs(TEST_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    print(\"Starting face analysis system...\")\n",
        "\n",
        "    # Process train dataset\n",
        "    print(\"\\n=== Processing TRAIN dataset ===\")\n",
        "    train_faces, train_matches = process_dataset(TRAIN_DIR, TRAIN_OUTPUT_DIR)\n",
        "\n",
        "    # Process test dataset\n",
        "    print(\"\\n=== Processing TEST dataset ===\")\n",
        "    test_faces, test_matches = process_dataset(TEST_DIR, TEST_OUTPUT_DIR)\n",
        "\n",
        "    # EDA for train dataset\n",
        "    basic_data_info(train_faces, \"TRAIN\")\n",
        "    visualize_face_quality_distribution(train_faces, \"TRAIN\")\n",
        "    check_missing_or_corrupted_faces(train_faces, \"TRAIN\")\n",
        "\n",
        "    # EDA for test dataset\n",
        "    basic_data_info(test_faces, \"TEST\")\n",
        "    visualize_face_quality_distribution(test_faces, \"TEST\")\n",
        "    check_missing_or_corrupted_faces(test_faces, \"TEST\")\n",
        "\n",
        "    # Compare statistics between train and test datasets\n",
        "    compare_train_test_statistics(train_faces, test_faces)\n",
        "\n",
        "    # Compare train representative faces with test representative faces\n",
        "    print(\"\\n=== Comparing TRAIN vs TEST datasets ===\")\n",
        "    face_system = FaceAnalysisSystem()\n",
        "    train_test_matches = face_system.compare_collections(train_faces, test_faces)\n",
        "\n",
        "    print(f\"Found {len(train_test_matches)} matches between train and test datasets\")\n",
        "\n",
        "    # Evaluate accuracy of train-test matches\n",
        "    face_system.evaluate_accuracy(train_test_matches)\n",
        "\n",
        "    # Visualize some train-test matches\n",
        "    vis_dir = os.path.join(DATASET_DIR, \"vis_train_vs_test\")\n",
        "    face_system.visualize_matches(train_test_matches, vis_dir, max_to_show=20)\n",
        "\n",
        "    # Save train-test matches\n",
        "    train_test_file = os.path.join(DATASET_DIR, \"train_test_matches.pkl\")\n",
        "    with open(train_test_file, 'wb') as f:\n",
        "        pickle.dump(train_test_matches, f)\n",
        "\n",
        "    print(f\"Saved train-test matches to {train_test_file}\")\n",
        "\n",
        "    print(\"\\nCompleted face analysis process.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9125e4a",
      "metadata": {
        "id": "c9125e4a",
        "outputId": "d1d7cfef-19d8-47b3-9fbb-5e43ab95c987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embeddings from /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/embeddings/train_embeddings.pkl\n",
            "Loading embeddings from /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/embeddings/test_embeddings.pkl\n",
            "Loaded 28708 train embeddings and 7176 test embeddings\n",
            "Emotion classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "\n",
            "=== Training Fast SVM Model ===\n",
            "Preparing data for fast SVM training...\n",
            "Training LinearSVC model (faster implementation)...\n",
            "Training completed in 10.62 seconds\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Evaluating model on test data...\n",
            "Prediction completed in 0.01 seconds\n",
            "Test accuracy: 0.4149\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.37      0.32      0.35       958\n",
            "     disgust       0.00      0.00      0.00       111\n",
            "        fear       0.35      0.08      0.13      1024\n",
            "       happy       0.45      0.71      0.55      1772\n",
            "     neutral       0.42      0.39      0.40      1233\n",
            "         sad       0.35      0.36      0.36      1247\n",
            "    surprise       0.47      0.48      0.47       831\n",
            "\n",
            "    accuracy                           0.41      7176\n",
            "   macro avg       0.34      0.33      0.32      7176\n",
            "weighted avg       0.40      0.41      0.39      7176\n",
            "\n",
            "Confusion matrix saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/svm_results_fast/confusion_matrix.png\n",
            "Model saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/svm_results_fast/emotion_svm_model.pkl\n",
            "\n",
            "=== Results Summary ===\n",
            "Overall accuracy: 0.4149\n",
            "\n",
            "Per-class performance:\n",
            "angry: Precision=0.374, Recall=0.323, F1=0.346, Support=958.0\n",
            "disgust: Precision=0.000, Recall=0.000, F1=0.000, Support=111.0\n",
            "fear: Precision=0.350, Recall=0.077, F1=0.126, Support=1024.0\n",
            "happy: Precision=0.447, Recall=0.709, F1=0.548, Support=1772.0\n",
            "neutral: Precision=0.415, Recall=0.394, F1=0.404, Support=1233.0\n",
            "sad: Precision=0.349, Recall=0.362, F1=0.355, Support=1247.0\n",
            "surprise: Precision=0.466, Recall=0.477, F1=0.471, Support=831.0\n",
            "\n",
            "Total processing time: 10.84 seconds\n",
            "\n",
            "All results saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/svm_results_fast\n",
            "Prediction script saved to /Users/abdelwahab/3rd-year/s2/7_emotion_dataset/svm_results_fast/emotion_predictor.py\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/abdelwahab/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/abdelwahab/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/abdelwahab/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/abdelwahab/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/abdelwahab/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/abdelwahab/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from time import time\n",
        "\n",
        "def load_embeddings(filepath):\n",
        "    \"\"\"Load embeddings from a pickle file.\"\"\"\n",
        "    print(f\"Loading embeddings from {filepath}\")\n",
        "    with open(filepath, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    return data[\"embeddings\"], data[\"labels\"]\n",
        "\n",
        "def train_svm_model_fast(train_embeddings, train_labels):\n",
        "    \"\"\"\n",
        "    Train an SVM model on the face embeddings with minimal computation time.\n",
        "    Uses LinearSVC which is much faster than the standard SVC.\n",
        "\n",
        "    Parameters:\n",
        "    - train_embeddings: numpy array of face embeddings\n",
        "    - train_labels: numpy array of emotion labels\n",
        "\n",
        "    Returns:\n",
        "    - trained SVM model\n",
        "    - scaler for preprocessing new data\n",
        "    \"\"\"\n",
        "    print(\"Preparing data for fast SVM training...\")\n",
        "\n",
        "    # Start timing\n",
        "    start_time = time()\n",
        "\n",
        "    # Preprocess embeddings - standardize features\n",
        "    scaler = StandardScaler()\n",
        "    scaled_embeddings = scaler.fit_transform(train_embeddings)\n",
        "\n",
        "    # Train Linear SVM model (much faster than RBF kernel)\n",
        "    print(\"Training LinearSVC model (faster implementation)...\")\n",
        "    model = LinearSVC(C=1.0, dual=\"auto\", random_state=42, max_iter=1000)\n",
        "    model.fit(scaled_embeddings, train_labels)\n",
        "\n",
        "    # End timing\n",
        "    training_time = time() - start_time\n",
        "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "    return model, scaler\n",
        "\n",
        "def evaluate_model(model, scaler, test_embeddings, test_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the trained SVM model on test data.\n",
        "\n",
        "    Parameters:\n",
        "    - model: trained SVM model\n",
        "    - scaler: fitted StandardScaler\n",
        "    - test_embeddings: numpy array of test face embeddings\n",
        "    - test_labels: numpy array of test emotion labels\n",
        "\n",
        "    Returns:\n",
        "    - accuracy: overall model accuracy\n",
        "    - report: classification report with precision, recall, f1-score\n",
        "    \"\"\"\n",
        "    print(\"Evaluating model on test data...\")\n",
        "\n",
        "    # Preprocess test embeddings\n",
        "    scaled_test_embeddings = scaler.transform(test_embeddings)\n",
        "\n",
        "    # Start timing\n",
        "    start_time = time()\n",
        "\n",
        "    # Predict on test data\n",
        "    predictions = model.predict(scaled_test_embeddings)\n",
        "\n",
        "    # End timing\n",
        "    prediction_time = time() - start_time\n",
        "    print(f\"Prediction completed in {prediction_time:.2f} seconds\")\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = np.mean(predictions == test_labels)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(test_labels, predictions, output_dict=True)\n",
        "\n",
        "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
        "    print(classification_report(test_labels, predictions))\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "    return accuracy, report, cm, predictions\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, save_path=None):\n",
        "    \"\"\"Plot and save confusion matrix.\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"Confusion matrix saved to {save_path}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.close()\n",
        "\n",
        "def save_model(model, scaler, class_names, filepath):\n",
        "    \"\"\"Save the trained model and scaler to a file.\"\"\"\n",
        "    model_data = {\n",
        "        'model': model,\n",
        "        'scaler': scaler,\n",
        "        'class_names': class_names\n",
        "    }\n",
        "\n",
        "    with open(filepath, 'wb') as f:\n",
        "        pickle.dump(model_data, f)\n",
        "\n",
        "    print(f\"Model saved to {filepath}\")\n",
        "\n",
        "def convert_to_probability_model(predictions, n_classes):\n",
        "    \"\"\"\n",
        "    Convert LinearSVC's decision function to probabilities.\n",
        "    This is a simple conversion and not as accurate as SVC's built-in probabilities.\n",
        "    \"\"\"\n",
        "    return np.exp(predictions) / np.sum(np.exp(predictions), axis=1, keepdims=True)\n",
        "\n",
        "def main():\n",
        "    # Start timing the entire process\n",
        "    total_start_time = time()\n",
        "\n",
        "    # Paths\n",
        "    DATASET_DIR = \"/Users/abdelwahab/3rd-year/s2/7_emotion_dataset\"\n",
        "    EMBEDDINGS_DIR = os.path.join(DATASET_DIR, \"embeddings\")\n",
        "    TRAIN_EMB_PATH = os.path.join(EMBEDDINGS_DIR, \"train_embeddings.pkl\")\n",
        "    TEST_EMB_PATH = os.path.join(EMBEDDINGS_DIR, \"test_embeddings.pkl\")\n",
        "\n",
        "    # Create output directory for results\n",
        "    RESULTS_DIR = os.path.join(DATASET_DIR, \"svm_results_fast\")\n",
        "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "    # Load train and test embeddings\n",
        "    try:\n",
        "        train_embeddings, train_labels = load_embeddings(TRAIN_EMB_PATH)\n",
        "        test_embeddings, test_labels = load_embeddings(TEST_EMB_PATH)\n",
        "\n",
        "        print(f\"Loaded {len(train_embeddings)} train embeddings and {len(test_embeddings)} test embeddings\")\n",
        "\n",
        "        # Get unique emotion classes\n",
        "        class_names = sorted(np.unique(np.concatenate([train_labels, test_labels])))\n",
        "        print(f\"Emotion classes: {class_names}\")\n",
        "\n",
        "        # Train SVM model with fast approach\n",
        "        print(\"\\n=== Training Fast SVM Model ===\")\n",
        "        model, scaler = train_svm_model_fast(train_embeddings, train_labels)\n",
        "\n",
        "        # Evaluate model\n",
        "        print(\"\\n=== Evaluating Model ===\")\n",
        "        accuracy, report, cm, predictions = evaluate_model(model, scaler, test_embeddings, test_labels)\n",
        "\n",
        "        # Plot and save confusion matrix\n",
        "        cm_path = os.path.join(RESULTS_DIR, \"confusion_matrix.png\")\n",
        "        plot_confusion_matrix(cm, class_names, save_path=cm_path)\n",
        "\n",
        "        # Save classification report\n",
        "        report_path = os.path.join(RESULTS_DIR, \"classification_report.pkl\")\n",
        "        with open(report_path, 'wb') as f:\n",
        "            pickle.dump(report, f)\n",
        "\n",
        "        # Save model\n",
        "        model_path = os.path.join(RESULTS_DIR, \"emotion_svm_model.pkl\")\n",
        "        save_model(model, scaler, class_names, model_path)\n",
        "\n",
        "        # Save predictions\n",
        "        pred_path = os.path.join(RESULTS_DIR, \"test_predictions.pkl\")\n",
        "        with open(pred_path, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'true_labels': test_labels,\n",
        "                'predictions': predictions\n",
        "            }, f)\n",
        "\n",
        "        print(\"\\n=== Results Summary ===\")\n",
        "        print(f\"Overall accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        # Print per-class performance\n",
        "        print(\"\\nPer-class performance:\")\n",
        "        for emotion in class_names:\n",
        "            precision = report[emotion]['precision']\n",
        "            recall = report[emotion]['recall']\n",
        "            f1 = report[emotion]['f1-score']\n",
        "            support = report[emotion]['support']\n",
        "\n",
        "            print(f\"{emotion}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}, Support={support}\")\n",
        "\n",
        "        # End timing the entire process\n",
        "        total_time = time() - total_start_time\n",
        "        print(f\"\\nTotal processing time: {total_time:.2f} seconds\")\n",
        "\n",
        "        print(f\"\\nAll results saved to {RESULTS_DIR}\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Make sure you've generated the embeddings first using the face embedding script.\")\n",
        "\n",
        "    # Create a simple prediction function for new faces\n",
        "    prediction_code = \"\"\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "import face_recognition\n",
        "import pickle\n",
        "\n",
        "def predict_emotion_from_image(image_path, model_data_path):\n",
        "    # Load the model data\n",
        "    with open(model_data_path, 'rb') as f:\n",
        "        model_data = pickle.load(f)\n",
        "\n",
        "    model = model_data['model']\n",
        "    scaler = model_data['scaler']\n",
        "    class_names = model_data['class_names']\n",
        "\n",
        "    # Extract face embedding from image\n",
        "    image = cv2.imread(image_path)\n",
        "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # For pre-cropped faces, use the entire image\n",
        "    h, w, _ = rgb_image.shape\n",
        "    face_location = [(0, w, h, 0)]  # top, right, bottom, left format\n",
        "\n",
        "    # Generate face encoding\n",
        "    face_encodings = face_recognition.face_encodings(rgb_image, face_location)\n",
        "\n",
        "    if not face_encodings:\n",
        "        return \"No face found\", 0.0\n",
        "\n",
        "    face_encoding = face_encodings[0]\n",
        "\n",
        "    # Preprocess the embedding\n",
        "    scaled_embedding = scaler.transform([face_encoding])\n",
        "\n",
        "    # Get prediction\n",
        "    emotion_label = model.predict(scaled_embedding)[0]\n",
        "\n",
        "    # Get decision values (not actual probabilities but will work for confidence)\n",
        "    decision_values = model.decision_function(scaled_embedding)\n",
        "\n",
        "    # For LinearSVC we don't have probabilities, so we use the decision value\n",
        "    # normalized across all classes as a confidence proxy\n",
        "    confidence_proxy = np.exp(decision_values) / np.sum(np.exp(decision_values))\n",
        "    max_confidence = np.max(confidence_proxy)\n",
        "\n",
        "    return emotion_label, max_confidence\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to your image and model\n",
        "    IMAGE_PATH = \"path/to/your/image.jpg\"\n",
        "    MODEL_PATH = \"path/to/emotion_svm_model.pkl\"\n",
        "\n",
        "    # Predict emotion\n",
        "    emotion, confidence = predict_emotion_from_image(IMAGE_PATH, MODEL_PATH)\n",
        "    print(f\"Predicted emotion: {emotion}\")\n",
        "    print(f\"Confidence: {confidence:.4f}\")\n",
        "\"\"\"\n",
        "\n",
        "    # Save the prediction code\n",
        "    pred_code_path = os.path.join(RESULTS_DIR, \"emotion_predictor.py\")\n",
        "    with open(pred_code_path, 'w') as f:\n",
        "        f.write(prediction_code)\n",
        "\n",
        "    print(f\"Prediction script saved to {pred_code_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da1dcc9f",
      "metadata": {
        "id": "da1dcc9f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a960b41",
      "metadata": {
        "id": "5a960b41"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6804d44e",
      "metadata": {
        "id": "6804d44e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}